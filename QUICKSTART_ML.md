# ðŸš€ QUICK START GUIDE - ML Quant Engine

## 5-Minute Setup

### 1. Verify Installation

```bash
# Check Python environment
python --version  # Should be 3.8+

# Verify packages installed
pip list | grep -E "torch|xgboost|sklearn|scipy"
```

### 2. Test Basic Functionality

```python
# test_ml_engine.py
from ml_quant_engine import ModelWeaknesses, DynamicWeightOptimizer

# Check weakness analysis
weaknesses = ModelWeaknesses()
print(weaknesses.generate_report())

# Check optimizer initialization
optimizer = DynamicWeightOptimizer()
print("Current weights:", optimizer.weights)

print("âœ… ML Engine functional!")
```

### 3. Run Simple Prediction

```python
# simple_prediction.py
from ml_quant_engine import RunningOrderPredictor

# Initialize predictor
predictor = RunningOrderPredictor()

# Sample horses (minimal features)
horses = [
    {
        'name': 'Fast Runner',
        'class': 2.0, 'form': 1.5, 'speed': 1.8, 'pace': 1.2,
        'style': 'E', 'style_numeric': 3, 'style_rating': 0.5,
        'post': 3, 'post_rating': 0.0,
        'angles': 0.3, 'quirin': 0.2,
        'jockey_win_pct': 0.18, 'trainer_win_pct': 0.22,
        'last_beyer': 85, 'avg_beyer': 82,
        'ml_odds': 3.5, 'current_odds': 3.2,
        'track_bias': 0.1, 'odds_drift': 0.086,
        'days_since_last': 14
    },
    {
        'name': 'Speed Demon',
        'class': 1.5, 'form': 2.0, 'speed': 2.2, 'pace': 0.8,
        'style': 'E/P', 'style_numeric': 2, 'style_rating': 0.3,
        'post': 1, 'post_rating': 0.1,
        'angles': 0.2, 'quirin': 0.1,
        'jockey_win_pct': 0.15, 'trainer_win_pct': 0.20,
        'last_beyer': 88, 'avg_beyer': 84,
        'ml_odds': 2.5, 'current_odds': 2.8,
        'track_bias': 0.15, 'odds_drift': -0.12,
        'days_since_last': 21
    },
    {
        'name': 'Closer King',
        'class': 1.8, 'form': 1.2, 'speed': 1.5, 'pace': 1.8,
        'style': 'S', 'style_numeric': 0, 'style_rating': 0.4,
        'post': 8, 'post_rating': -0.2,
        'angles': 0.4, 'quirin': 0.3,
        'jockey_win_pct': 0.20, 'trainer_win_pct': 0.25,
        'last_beyer': 83, 'avg_beyer': 81,
        'ml_odds': 4.0, 'current_odds': 3.5,
        'track_bias': -0.05, 'odds_drift': 0.125,
        'days_since_last': 30
    }
]

# Note: Must train before predicting (or use pre-trained model)
# For quick test, models need training data
print("Note: Run full optimization first to train models")
print("See: python run_optimization.py")
```

---

## Full Optimization Workflow

### Option A: Run Complete Pipeline (Recommended)

```bash
# This will:
# 1. Analyze weaknesses
# 2. Generate 200 training races
# 3. Optimize weights
# 4. Train ensemble
# 5. Run backtest
# 6. Generate deliverables

python run_optimization.py
```

**Output:**
- `optimized_weights.csv` - Weight comparison
- `ensemble_model.py` - Production code
- `example_predictions.csv` - Sample predictions
- `backtest_report.txt` - Metrics
- `optimization_summary.json` - JSON summary

**Time:** ~5-10 minutes

---

### Option B: Step-by-Step Manual

#### Step 1: Weight Optimization Only

```python
from ml_quant_engine import DynamicWeightOptimizer
from backtest_simulator import RaceSimulator

# Generate training data
simulator = RaceSimulator(n_races=200)
races = simulator.generate_races()

# Optimize weights
optimizer = DynamicWeightOptimizer()
optimized = optimizer.optimize_weights(
    races,
    method='bayesian',  # or 'gradient' or 'grid'
    n_iterations=50
)

print("Optimized Weights:")
for comp, weight in optimized.items():
    print(f"  {comp}: {weight:.3f}")

# Save results
import pandas as pd
df = optimizer.generate_weights_table()
df.to_csv('my_weights.csv', index=False)
```

#### Step 2: Train Ensemble

```python
from ml_quant_engine import RunningOrderPredictor

# Initialize and train
predictor = RunningOrderPredictor()
predictor.train(races, n_epochs=50)

print("âœ… Ensemble trained")
```

#### Step 3: Make Predictions

```python
# Predict race
predictions = predictor.predict_running_order(
    horses=my_horses,
    track="Gulfstream",
    surface="Dirt",
    distance="8f"
)

print(predictions)
```

#### Step 4: Backtest

```python
from backtest_simulator import BacktestEngine

# Run backtest
engine = BacktestEngine(predictor)
results = engine.run_backtest()

print(results)

# Save report
report = engine.generate_report(results, save_path='my_backtest.txt')
```

---

## Integration with Existing System

### Link to app.py Rating Engine

```python
# In app.py, add:

from ml_quant_engine import RunningOrderPredictor

# Load pre-trained model
@st.cache_resource
def load_ml_predictor():
    predictor = RunningOrderPredictor()
    # Load saved model weights if available
    try:
        predictor.ensemble.load_state_dict(torch.load('saved_model.pth'))
    except:
        pass  # Use default if no saved model
    return predictor

predictor = load_ml_predictor()

# In race analysis section:
def predict_race_order(horses_df):
    """Enhance ratings with ML predictions"""
    
    # Convert DataFrame to horse dicts
    horses = []
    for _, row in horses_df.iterrows():
        horse = {
            'name': row['Horse'],
            'class': row.get('class_rating', 0),
            'form': row.get('form_rating', 0),
            'speed': row.get('speed_rating', 0),
            'pace': row.get('pace_rating', 0),
            'style': row.get('RunStyle', 'P'),
            'style_numeric': {'E': 3, 'E/P': 2, 'P': 1, 'S': 0}.get(row.get('RunStyle', 'P'), 1),
            'style_rating': row.get('style_rating', 0),
            'post': row.get('post_position', 1),
            'post_rating': row.get('post_rating', 0),
            'angles': row.get('angles', 0),
            # ... more features
        }
        horses.append(horse)
    
    # Get ML predictions
    ml_predictions = predictor.predict_running_order(
        horses,
        track=st.session_state.get('track', 'Unknown'),
        surface=st.session_state.get('surface', 'Dirt'),
        distance=st.session_state.get('distance', '8f')
    )
    
    return ml_predictions
```

---

## Troubleshooting

### Issue: "No module named 'torch'"
```bash
pip install torch xgboost scikit-learn scipy matplotlib
```

### Issue: "Winner accuracy too low"
**Cause:** Training on synthetic data (200 races)

**Solution:** Load historical races:
```python
import sqlite3
import pandas as pd

conn = sqlite3.connect('race_history.db')
historical = pd.read_sql('SELECT * FROM races', conn)

# Convert to training format and retrain
```

### Issue: "Too many contenders (7.8 for 2nd place)"
**Cause:** Probability thresholds too low

**Solution:** Adjust thresholds:
```python
# In backtest_simulator.py, line ~340
second_contenders.append(np.sum(second_probs >= 0.20))  # Was 0.15
third_contenders.append(np.sum(third_probs >= 0.15))    # Was 0.10
```

### Issue: "Calibration error high (0.217)"
**Cause:** Temperature scaling needs tuning

**Solution:** Adjust softmax temperature:
```python
# In ml_quant_engine.py, EnsemblePredictor.predict_ensemble()
probs = torch.nn.functional.softmax(combined / 5.0, dim=1)  # Was 3.0
```

---

## Performance Tuning

### For Maximum Accuracy (Slower)

```python
# Extended training
predictor.train(races, n_epochs=200)

# More ensemble models
predictor.xgb_model.n_estimators = 500
predictor.rf_model.n_estimators = 500

# More optimization iterations
optimizer.optimize_weights(races, n_iterations=100)
```

### For Speed (Lower Accuracy)

```python
# Quick training
predictor.train(races, n_epochs=20)

# Fewer trees
predictor.xgb_model.n_estimators = 50
predictor.rf_model.n_estimators = 50

# Quick optimization
optimizer.optimize_weights(races, method='gradient', n_iterations=20)
```

---

## Expected Performance

### With Synthetic Data (Current)
- Winner Accuracy: 52.0%
- ROI: +17.5%
- Training Time: 5 minutes

### With 1000 Historical Races (Projected)
- Winner Accuracy: 75-82%
- ROI: +25-35%
- Training Time: 15-20 minutes

### With 5000 Historical Races + Advanced Features (Target)
- Winner Accuracy: 88-95%
- ROI: +40-60%
- Training Time: 1-2 hours

---

## Next Steps

1. **Immediate (Week 1):**
   - âœ… System tested with synthetic data
   - ðŸ”„ Load historical races from database
   - ðŸ”„ Retrain with 1000+ real races

2. **Short-term (Weeks 2-3):**
   - Expand track bias database
   - Add trip notes parsing
   - Integrate with live odds feed

3. **Medium-term (Months 2-3):**
   - Implement LSTM for sequence modeling
   - Add continuous learning pipeline
   - Deploy to production with real-time predictions

---

## Files Reference

| File | Purpose |
|------|---------|
| `ml_quant_engine.py` | Core optimization + ensemble |
| `backtest_simulator.py` | 200-race validation framework |
| `run_optimization.py` | Complete pipeline executor |
| `ensemble_model.py` | **Generated** production code |
| `optimized_weights.csv` | **Generated** weight table |
| `ML_OPTIMIZATION_GUIDE.md` | Complete documentation |
| `OPTIMIZATION_RESULTS.md` | Detailed results analysis |
| `SYSTEM_ARCHITECTURE.txt` | Visual system overview |

---

## Support & Documentation

- **Full Guide**: See `ML_OPTIMIZATION_GUIDE.md`
- **Results**: See `OPTIMIZATION_RESULTS.md`
- **Architecture**: See `SYSTEM_ARCHITECTURE.txt`

---

**Last Updated**: December 2024  
**Version**: 1.0.0  
**Status**: âœ… Ready for Production Data Integration
