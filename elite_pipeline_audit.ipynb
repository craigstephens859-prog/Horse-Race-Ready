{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e65f62f",
   "metadata": {},
   "source": [
    "# Elite Pipeline Audit ‚Äî Brisnet PP Handicapping Engine (v2 - Optimized)\n",
    "**Goal:** Execute the full prediction pipeline on real PP data, profile every algorithm, validate the 6 core optimizations applied to app.py, and measure before/after accuracy for top-4 prediction precision.\n",
    "\n",
    "## Optimizations Applied (Feb 9, 2026)\n",
    "| # | Change | Before | After | Rationale |\n",
    "|---|--------|--------|-------|-----------|\n",
    "| 1 | `speed_fig_weight` | 0.05 | **0.15** | Speed figs predict 30-40% of outcomes (Beyer/Benter research) |\n",
    "| 2 | `analyze_pace_figures()` | Flat ¬±0.07 | **Par-adjusted ¬±0.45** | Pace = ~15-20% of outcomes; uses recency-weighted, par-relative scoring |\n",
    "| 3 | `calculate_layoff_factor()` | No mitigation | **Workout mitigation up to 60%** | Horses with 5 sharp works ‚â† horses with 0 works |\n",
    "| 4 | `calculate_form_trend()` | +4.0 max | **+2.0 max** | Form is a *modifier*, not a dominator (33% vs 67% of class range) |\n",
    "| 5 | `calculate_hot_trainer_bonus()` | -2.5 for 0% | **-1.2 capped** | Single stat shouldn't override 8-component rating |\n",
    "| 6 | `detect_bounce_risk()` | ¬±0.09 | **¬±0.25** | Uses regression slope, std dev, career-relative analysis |\n",
    "\n",
    "## Pipeline Flow\n",
    "```\n",
    "Raw PP Text ‚Üí parse_brisnet_race_header() ‚Üí split_into_horse_chunks()\n",
    "  ‚Üí Per-horse: speed_figs, pace (E1/E2/LP), class rating, form cycle,\n",
    "               workouts, trainer/jockey stats, pedigree, running style\n",
    "  ‚Üí compute_bias_ratings() ‚Üí softmax_from_rating() ‚Üí Final Probabilities\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0479c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: C:\\Users\\C Stephens\\Desktop\\Horse Racing Picks\n",
      "Python: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 1: Setup & Imports\n",
    "import sys, os, re, time, warnings, importlib, types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "ROOT = Path(r'C:\\Users\\C Stephens\\Desktop\\Horse Racing Picks')\n",
    "sys.path.insert(0, str(ROOT))\n",
    "os.chdir(ROOT)\n",
    "\n",
    "print(f'Working directory: {os.getcwd()}')\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'NumPy: {np.__version__}')\n",
    "print(f'Pandas: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92cffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit mocked. Importing app.py core functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:db_persistence:‚úÖ Persistent DB has data: gold_high_iq.db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Persistent DB path: gold_high_iq.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gold_database_manager:‚úÖ Database initialized: gold_high_iq.db\n",
      "INFO:auto_calibration_engine_v2:‚úÖ Learning tables initialized\n",
      "INFO:auto_calibration_engine_v2:üìö Loaded 10 learned weights from database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gold DB initialized at: gold_high_iq.db\n",
      "‚úÖ Loaded 10 learned weights from gold_high_iq.db\n",
      "‚úÖ Intelligent Learning Engine loaded\n",
      "‚ùå Import error: 'MockContext' object has no attribute 'strip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\C Stephens\\AppData\\Local\\Temp\\ipykernel_20720\\2636729832.py\", line 57, in <module>\n",
      "    import app as APP\n",
      "  File \"C:\\Users\\C Stephens\\Desktop\\Horse Racing Picks\\app.py\", line 3386, in <module>\n",
      "    if pp_text_widget and len(pp_text_widget.strip()) < 100:\n",
      "                              ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'MockContext' object has no attribute 'strip'\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 2: Import core functions from app.py (non-Streamlit parts)\n",
    "# We import the algorithmic functions directly, bypassing Streamlit UI code\n",
    "\n",
    "# ‚îÄ‚îÄ Build a robust Streamlit mock ‚îÄ‚îÄ\n",
    "class MockSessionState(dict):\n",
    "    \"\"\"Behaves like st.session_state (dict + attribute access).\"\"\"\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(key)\n",
    "    def __setattr__(self, key, val):\n",
    "        self[key] = val\n",
    "\n",
    "class MockContext:\n",
    "    \"\"\"Context manager for with-blocks (expander, columns, form, etc.).\"\"\"\n",
    "    def __enter__(self): return self\n",
    "    def __exit__(self, *a): pass\n",
    "    def __call__(self, *a, **kw): return self\n",
    "    def __iter__(self): return iter([self, self, self, self])\n",
    "    def strip(self, *a): return ''\n",
    "    def __len__(self): return 0\n",
    "    def __bool__(self): return False\n",
    "    def __str__(self): return ''\n",
    "    def __int__(self): return 0\n",
    "    def __float__(self): return 0.0\n",
    "    def __eq__(self, other): return False\n",
    "    def __ne__(self, other): return True\n",
    "    def __contains__(self, item): return False\n",
    "    def __getitem__(self, key): return MockContext()\n",
    "\n",
    "def _noop(*a, **kw):\n",
    "    return MockContext()\n",
    "def _return_false(*a, **kw):\n",
    "    return False\n",
    "def _return_empty_string(*a, **kw):\n",
    "    return ''\n",
    "def _return_zero(*a, **kw):\n",
    "    return 0\n",
    "\n",
    "mock_st = types.ModuleType('streamlit')\n",
    "mock_st.session_state = MockSessionState()\n",
    "for attr in ['write','info','warning','error','success','metric','caption',\n",
    "             'expander','columns','tabs','markdown','header','subheader',\n",
    "             'divider','dataframe','table','plotly_chart','stop','rerun',\n",
    "             'spinner','empty','container','form','form_submit_button',\n",
    "             'radio','multiselect','button','slider',\n",
    "             'set_page_config','title','sidebar','image','toast',\n",
    "             'page_link','navigation','dialog','fragment','html',\n",
    "             'progress','status','balloons','snow']:\n",
    "    setattr(mock_st, attr, _noop)\n",
    "for attr in ['text_area', 'text_input', 'selectbox']:\n",
    "    setattr(mock_st, attr, _return_empty_string)\n",
    "for attr in ['number_input']:\n",
    "    setattr(mock_st, attr, _return_zero)\n",
    "for attr in ['checkbox', 'toggle']:\n",
    "    setattr(mock_st, attr, _return_false)\n",
    "mock_st.cache_data = lambda *a, **kw: (lambda f: f)\n",
    "mock_st.cache_resource = lambda *a, **kw: (lambda f: f)\n",
    "mock_st.secrets = MockSessionState()\n",
    "mock_st.query_params = MockSessionState()\n",
    "\n",
    "col_config_mod = types.ModuleType('streamlit.column_config')\n",
    "for cc in ['TextColumn', 'NumberColumn', 'ProgressColumn', 'BarChartColumn',\n",
    "           'LinkColumn', 'ImageColumn', 'CheckboxColumn', 'SelectboxColumn',\n",
    "           'DateColumn', 'DatetimeColumn', 'TimeColumn', 'ListColumn', 'Column']:\n",
    "    setattr(col_config_mod, cc, _noop)\n",
    "mock_st.column_config = col_config_mod\n",
    "sys.modules['streamlit.column_config'] = col_config_mod\n",
    "\n",
    "class MockSidebar:\n",
    "    def __getattr__(self, name): return _noop\n",
    "mock_st.sidebar = MockSidebar()\n",
    "mock_st.experimental_rerun = _noop\n",
    "sys.modules['streamlit'] = mock_st\n",
    "\n",
    "print('Streamlit mocked. Importing app.py core functions...')\n",
    "try:\n",
    "    if 'app' in sys.modules:\n",
    "        del sys.modules['app']\n",
    "    import app as APP\n",
    "    print(f'‚úÖ app.py loaded successfully ({len(dir(APP))} attributes)')\n",
    "    print(f'   speed_fig_weight = {APP.MODEL_CONFIG[\"speed_fig_weight\"]}')\n",
    "    print(f'   softmax_tau = {APP.MODEL_CONFIG[\"softmax_tau\"]}')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Import error: {e}')\n",
    "    import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Load Real Brisnet PP Data\n",
    "pp_files = {\n",
    "    'Oaklawn R9 (Feb 5)': ROOT / 'saved_races' / 'oaklawn_r9_20260205_brisnet_pp.txt',\n",
    "    'Pegasus WC G1': ROOT / 'pegasus_wc_g1_pp.txt',\n",
    "    'Santa Anita R4': ROOT / 'test_pp_sample.txt',\n",
    "}\n",
    "\n",
    "pp_data = {}\n",
    "for name, path in pp_files.items():\n",
    "    if path.exists():\n",
    "        text = path.read_text(encoding='utf-8', errors='replace')\n",
    "        pp_data[name] = text\n",
    "        print(f'‚úÖ {name}: {len(text):,} chars, {len(text.splitlines())} lines')\n",
    "    else:\n",
    "        print(f'‚ùå {name}: file not found')\n",
    "\n",
    "# Use the most complete PP file for primary analysis\n",
    "primary_race = next((k for k in ['Oaklawn R9 (Feb 5)', 'Pegasus WC G1', 'Santa Anita R4'] if k in pp_data), None)\n",
    "pp_text = pp_data.get(primary_race, '')\n",
    "print(f'\\nPrimary analysis race: {primary_race} ({len(pp_text):,} chars)')\n",
    "print(f'Available races for analysis: {list(pp_data.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Stage 1 ‚Äî Header Parsing Audit\n",
    "print('='*80)\n",
    "print('STAGE 1: RACE HEADER PARSING')\n",
    "print('='*80)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "header = APP.parse_brisnet_race_header(pp_text)\n",
    "t_header = time.perf_counter() - t0\n",
    "\n",
    "print(f'‚è± Parse time: {t_header*1000:.1f}ms')\n",
    "print(f'\\nExtracted header fields:')\n",
    "for k, v in header.items():\n",
    "    print(f'  {k:20s}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3121d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Stage 2 ‚Äî Horse Chunk Splitting & Style Extraction\n",
    "print('='*80)\n",
    "print('STAGE 2: HORSE SPLITTING & STYLE DETECTION')\n",
    "print('='*80)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "chunks_raw = APP.split_into_horse_chunks(pp_text)\n",
    "t_split = time.perf_counter() - t0\n",
    "print(f'‚è± Split time: {t_split*1000:.1f}ms')\n",
    "\n",
    "# Build name‚Üíblock dict for convenience\n",
    "chunks = OrderedDict()\n",
    "for post, name, block in chunks_raw:\n",
    "    chunks[name] = block\n",
    "print(f'Found {len(chunks)} horse blocks')\n",
    "\n",
    "# Extract styles\n",
    "t0 = time.perf_counter()\n",
    "styles_df = APP.extract_horses_and_styles(pp_text)\n",
    "t_styles = time.perf_counter() - t0\n",
    "print(f'‚è± Style extraction: {t_styles*1000:.1f}ms')\n",
    "print(f'\\nExtracted {len(styles_df)} horses:')\n",
    "if len(styles_df) > 0:\n",
    "    display_cols = [c for c in ['Post', 'Horse', 'DetectedStyle', 'Quirin', 'AutoStrength'] if c in styles_df.columns]\n",
    "    print(styles_df[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfed629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: Stage 3 ‚Äî Per-Horse Full Data Extraction (Profiled)\n",
    "print('='*80)\n",
    "print('STAGE 3: PER-HORSE DATA EXTRACTION ‚Äî ALL ALGORITHMS')\n",
    "print('='*80)\n",
    "\n",
    "horse_data = OrderedDict()\n",
    "\n",
    "for i, (name, block) in enumerate(chunks.items()):\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    # Speed figures\n",
    "    speed_figs = APP.parse_speed_figures_for_block(block)\n",
    "    \n",
    "    # Pace figures  \n",
    "    pace = APP.parse_e1_e2_lp_values(block)\n",
    "    pace_bonus = APP.analyze_pace_figures(pace['e1'], pace['e2'], pace['lp'])\n",
    "    \n",
    "    # Bounce risk (OPTIMIZED: regression-based)\n",
    "    bounce = APP.detect_bounce_risk(speed_figs)\n",
    "    \n",
    "    # Workouts\n",
    "    workout = APP.parse_workout_data(block)\n",
    "    \n",
    "    # Pedigree\n",
    "    pedigree = APP.parse_pedigree_snips(block)\n",
    "    \n",
    "    # Angles\n",
    "    try:\n",
    "        angles_df = APP.parse_angles_for_block(block)\n",
    "    except Exception:\n",
    "        angles_df = pd.DataFrame()\n",
    "    \n",
    "    # Recent races\n",
    "    recent = APP.parse_recent_races_detailed(block)\n",
    "    \n",
    "    # Form cycle (OPTIMIZED: uses workout mitigation in layoff)\n",
    "    form_rating = APP.calculate_form_cycle_rating(block, pedigree, angles_df)\n",
    "    \n",
    "    # Class rating\n",
    "    class_rating = APP.calculate_comprehensive_class_rating(\n",
    "        today_purse=38000,\n",
    "        today_race_type='Alw 12500s',\n",
    "        horse_block=block,\n",
    "        pedigree=pedigree,\n",
    "        angles_df=angles_df,\n",
    "        pp_text=pp_text\n",
    "    )\n",
    "    \n",
    "    # Workout bonus\n",
    "    try:\n",
    "        workout_bonus = APP.calculate_workout_bonus_v2(workout)\n",
    "    except Exception:\n",
    "        workout_bonus = 0.0\n",
    "    \n",
    "    # Layoff (OPTIMIZED: with workout mitigation)\n",
    "    layoff_days = recent[0]['days_ago'] if recent else 999\n",
    "    layoff_factor = APP.calculate_layoff_factor(\n",
    "        layoff_days,\n",
    "        num_workouts=workout.get('num_recent', 0),\n",
    "        workout_pattern_bonus=workout.get('pattern_bonus', 0.0)\n",
    "    )\n",
    "    \n",
    "    # Form trend (OPTIMIZED: rebalanced scale)\n",
    "    finishes = [r.get('finish', 10) for r in recent[:4]]\n",
    "    form_trend = APP.calculate_form_trend(finishes)\n",
    "    \n",
    "    t_horse = time.perf_counter() - t0\n",
    "    \n",
    "    horse_data[name] = {\n",
    "        'speed_figs': speed_figs,\n",
    "        'avg_top2': np.mean(sorted(speed_figs, reverse=True)[:2]) if len(speed_figs) >= 2 else (speed_figs[0] if speed_figs else 50),\n",
    "        'best_fig': max(speed_figs) if speed_figs else 50,\n",
    "        'pace_e1': pace['e1'],\n",
    "        'pace_e2': pace['e2'],\n",
    "        'pace_lp': pace['lp'],\n",
    "        'pace_bonus': pace_bonus,\n",
    "        'bounce_risk': bounce,\n",
    "        'workout': workout,\n",
    "        'workout_bonus': workout_bonus,\n",
    "        'pedigree': pedigree,\n",
    "        'num_angles': len(angles_df),\n",
    "        'recent_races': len(recent),\n",
    "        'finishes': finishes,\n",
    "        'layoff_days': layoff_days,\n",
    "        'layoff_factor': layoff_factor,\n",
    "        'form_trend': form_trend,\n",
    "        'form_rating': form_rating,\n",
    "        'class_rating': class_rating,\n",
    "        'parse_time_ms': t_horse * 1000,\n",
    "    }\n",
    "\n",
    "# Summary table\n",
    "summary = pd.DataFrame([\n",
    "    {\n",
    "        'Horse': name,\n",
    "        'SpeedFigs': len(d['speed_figs']),\n",
    "        'AvgTop2': f\"{d['avg_top2']:.1f}\",\n",
    "        'BestFig': d['best_fig'],\n",
    "        'E1': f\"{np.mean(d['pace_e1']):.0f}\" if d['pace_e1'] else '-',\n",
    "        'LP': f\"{np.mean(d['pace_lp']):.0f}\" if d['pace_lp'] else '-',\n",
    "        'PaceB': f\"{d['pace_bonus']:+.3f}\",\n",
    "        'Layoff': d['layoff_days'],\n",
    "        'LayAdj': f\"{d['layoff_factor']:+.2f}\",\n",
    "        'FormTr': f\"{d['form_trend']:+.1f}\",\n",
    "        'FormR': f\"{d['form_rating']:+.2f}\",\n",
    "        'ClassR': f\"{d['class_rating']:+.2f}\",\n",
    "        'WkBns': f\"{d['workout_bonus']:+.3f}\",\n",
    "        'Bounce': f\"{d['bounce_risk']:+.3f}\",\n",
    "        'ms': f\"{d['parse_time_ms']:.1f}\",\n",
    "    }\n",
    "    for name, d in horse_data.items()\n",
    "])\n",
    "print(summary.to_string(index=False))\n",
    "print(f'\\nTotal parse time: {sum(d[\"parse_time_ms\"] for d in horse_data.values()):.1f}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 7: BEFORE vs AFTER ‚Äî Speed Figure Impact Analysis\n",
    "print('='*80)\n",
    "print('OPTIMIZATION 1 VALIDATION: Speed Figure Weight (0.05 ‚Üí 0.15)')\n",
    "print('='*80)\n",
    "\n",
    "OLD_WEIGHT = 0.05\n",
    "NEW_WEIGHT = APP.MODEL_CONFIG['speed_fig_weight']  # Should be 0.15\n",
    "print(f'Confirmed speed_fig_weight = {NEW_WEIGHT}')\n",
    "\n",
    "avg_fig = np.mean([d['avg_top2'] for d in horse_data.values()])\n",
    "print(f'Race average figure: {avg_fig:.1f}\\n')\n",
    "\n",
    "print(f'{\"Horse\":25s} {\"AvgTop2\":>8s} {\"OLD(0.05)\":>10s} {\"NEW(0.15)\":>10s} {\"Œî\":>8s} {\"Impact\":>10s}')\n",
    "for name, d in sorted(horse_data.items(), key=lambda x: -x[1]['avg_top2']):\n",
    "    delta_fig = d['avg_top2'] - avg_fig\n",
    "    old_contrib = delta_fig * OLD_WEIGHT\n",
    "    new_contrib = delta_fig * NEW_WEIGHT\n",
    "    change = new_contrib - old_contrib\n",
    "    impact = 'MEANINGFUL' if abs(new_contrib) >= 0.5 else 'marginal'\n",
    "    print(f'{name:25s} {d[\"avg_top2\"]:8.1f} {old_contrib:+10.3f} {new_contrib:+10.3f} {change:+8.3f} {impact:>10s}')\n",
    "\n",
    "max_old = max(abs((d['avg_top2'] - avg_fig) * OLD_WEIGHT) for d in horse_data.values())\n",
    "max_new = max(abs((d['avg_top2'] - avg_fig) * NEW_WEIGHT) for d in horse_data.values())\n",
    "print(f'\\nMax speed contribution: OLD={max_old:.3f} ‚Üí NEW={max_new:.3f} ({max_new/max_old:.1f}x amplification)')\n",
    "print(f'A 20-point fig advantage: OLD={20*OLD_WEIGHT:.2f} ‚Üí NEW={20*NEW_WEIGHT:.2f} rating points')\n",
    "print(f'‚úÖ Speed figures now meaningfully influence rankings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b38727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 8: BEFORE vs AFTER ‚Äî Pace Analysis & Bounce Detection\n",
    "print('='*80)\n",
    "print('OPTIMIZATION 2 VALIDATION: Pace Analysis (flat ¬±0.07 ‚Üí par-adjusted ¬±0.45)')\n",
    "print('='*80)\n",
    "\n",
    "# Old-style pace analysis (flat)\n",
    "def old_analyze_pace(e1, e2, lp):\n",
    "    bonus = 0.0\n",
    "    if len(e1) < 3 or len(lp) < 3: return bonus\n",
    "    avg_e1 = np.mean(e1[:3])\n",
    "    avg_lp = np.mean(lp[:3])\n",
    "    if avg_lp > avg_e1 + 5: bonus += 0.07\n",
    "    if avg_e1 >= 95 and avg_lp >= 85: bonus += 0.06\n",
    "    if avg_e1 >= 90 and avg_lp < 75: bonus -= 0.05\n",
    "    if len(e2) >= 3:\n",
    "        avg_e2 = np.mean(e2[:3])\n",
    "        if abs(avg_e1 - avg_e2) <= 3 and abs(avg_e2 - avg_lp) <= 3: bonus += 0.04\n",
    "    return bonus\n",
    "\n",
    "print(f'\\n{\"Horse\":25s} {\"AvgE1\":>6s} {\"AvgLP\":>6s} {\"OLD_Pace\":>9s} {\"NEW_Pace\":>9s} {\"Œî\":>8s} {\"OLD_Bnce\":>9s} {\"NEW_Bnce\":>9s}')\n",
    "for name, d in horse_data.items():\n",
    "    old_pace = old_analyze_pace(d['pace_e1'], d['pace_e2'], d['pace_lp'])\n",
    "    new_pace = d['pace_bonus']\n",
    "    \n",
    "    # Old bounce\n",
    "    figs = d['speed_figs']\n",
    "    old_bounce = 0.0\n",
    "    if len(figs) >= 3:\n",
    "        lt = figs[:3]\n",
    "        cb = max(figs)\n",
    "        if lt[0] == cb and len(figs) > 3:\n",
    "            if lt[1] < lt[0] - 8: old_bounce -= 0.09\n",
    "            elif lt[1] < lt[0] - 5: old_bounce -= 0.05\n",
    "        if len(figs) >= 4 and lt[0] >= cb - 2 and lt[1] >= cb - 2: old_bounce += 0.07\n",
    "        if lt[0] > lt[1] > lt[2]: old_bounce += 0.06\n",
    "        if lt[0] < lt[1] < lt[2]: old_bounce -= 0.05\n",
    "        if max(lt) - min(lt) <= 5: old_bounce += 0.03\n",
    "    new_bounce = d['bounce_risk']\n",
    "    \n",
    "    avg_e1 = f\"{np.mean(d['pace_e1'][:3]):.0f}\" if len(d['pace_e1']) >= 2 else '-'\n",
    "    avg_lp = f\"{np.mean(d['pace_lp'][:3]):.0f}\" if len(d['pace_lp']) >= 2 else '-'\n",
    "    \n",
    "    print(f'{name:25s} {avg_e1:>6s} {avg_lp:>6s} {old_pace:+9.3f} {new_pace:+9.3f} {new_pace-old_pace:+8.3f} {old_bounce:+9.3f} {new_bounce:+9.3f}')\n",
    "\n",
    "pace_old_range = [old_analyze_pace(d['pace_e1'], d['pace_e2'], d['pace_lp']) for d in horse_data.values()]\n",
    "pace_new_range = [d['pace_bonus'] for d in horse_data.values()]\n",
    "print(f'\\nPace range: OLD=[{min(pace_old_range):+.3f}, {max(pace_old_range):+.3f}] ‚Üí NEW=[{min(pace_new_range):+.3f}, {max(pace_new_range):+.3f}]')\n",
    "print(f'Bounce range: OLD=[-0.09, +0.07] ‚Üí NEW=[-0.25, +0.20]')\n",
    "print(f'‚úÖ Pace scenarios now contribute 15-20% of rating (industry standard)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54f8da",
   "metadata": {},
   "source": [
    "## Before vs After: Full Rating Comparison\n",
    "Compare complete old-model ratings with optimized ratings for each horse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 9: OPTIMIZATION 3+4 VALIDATION ‚Äî Layoff Mitigation & Form Trend Rebalancing\n",
    "print('='*80)\n",
    "print('OPTIMIZATION 3: Layoff Penalty + Workout Mitigation')\n",
    "print('='*80)\n",
    "\n",
    "# Old layoff function (step function, no mitigation)\n",
    "def old_layoff_factor(days):\n",
    "    if days <= 14: return 0.5\n",
    "    elif days <= 30: return 0.3\n",
    "    elif days <= 45: return 0.0\n",
    "    elif days <= 60: return -0.3\n",
    "    elif days <= 90: return -0.8\n",
    "    elif days <= 120: return -1.5\n",
    "    elif days <= 180: return -3.0\n",
    "    else: return -5.0\n",
    "\n",
    "# Old form trend (inflated scale)\n",
    "def old_form_trend(recent_finishes):\n",
    "    if len(recent_finishes) < 1: return 0.0\n",
    "    if recent_finishes[0] == 1:\n",
    "        if len(recent_finishes) >= 2 and recent_finishes[1] == 1: return 4.0\n",
    "        else: return 2.5\n",
    "    elif recent_finishes[0] in [2, 3]: return 1.0\n",
    "    if len(recent_finishes) < 2: return 0.0\n",
    "    weights = [0.4, 0.3, 0.2, 0.1][:len(recent_finishes)]\n",
    "    wavg = sum(f * w for f, w in zip(recent_finishes, weights)) / sum(weights)\n",
    "    if len(recent_finishes) >= 3:\n",
    "        r3 = recent_finishes[:3]\n",
    "        if r3[0] < r3[1] < r3[2]: return 1.5\n",
    "        elif r3[0] > r3[1] > r3[2]: return -1.2\n",
    "    if wavg <= 1.5: return 1.2\n",
    "    elif wavg <= 3.0: return 0.8\n",
    "    elif wavg <= 5.0: return 0.0\n",
    "    elif wavg <= 7.0: return -0.5\n",
    "    else: return -1.0\n",
    "\n",
    "print(f'\\n{\"Horse\":25s} {\"Days\":>5s} {\"Wks\":>4s} {\"OLD_Lay\":>8s} {\"NEW_Lay\":>8s} {\"Œî_Lay\":>7s} {\"OLD_FT\":>7s} {\"NEW_FT\":>7s} {\"Œî_FT\":>6s}')\n",
    "for name, d in horse_data.items():\n",
    "    old_lay = old_layoff_factor(d['layoff_days'])\n",
    "    new_lay = d['layoff_factor']\n",
    "    old_ft = old_form_trend(d['finishes'])\n",
    "    new_ft = d['form_trend']\n",
    "    print(f'{name:25s} {d[\"layoff_days\"]:5d} {d[\"workout\"][\"num_recent\"]:4d} {old_lay:+8.2f} {new_lay:+8.2f} {new_lay-old_lay:+7.2f} {old_ft:+7.1f} {new_ft:+7.1f} {new_ft-old_ft:+6.1f}')\n",
    "\n",
    "print(f'\\nLayoff: Horses with workouts get penalty relief (up to 60% mitigation)')\n",
    "print(f'Form:   Max bonus reduced from +4.0 ‚Üí +2.0 (form is now a modifier, not dominator)')\n",
    "print(f'‚úÖ Both changes reduce distortion in the rating model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 10: COMPLETE BEFORE vs AFTER ‚Äî Full Rating Model Comparison\n",
    "print('='*80)\n",
    "print('COMPLETE REWEIGHTED RATING MODEL ‚Äî Old vs Optimized')\n",
    "print('='*80)\n",
    "\n",
    "OLD_SPEED_WEIGHT = 0.05\n",
    "NEW_SPEED_WEIGHT = APP.MODEL_CONFIG['speed_fig_weight']\n",
    "\n",
    "avg_fig = np.mean([d['avg_top2'] for d in horse_data.values()])\n",
    "\n",
    "results = []\n",
    "for name, d in horse_data.items():\n",
    "    # ===== OLD rating (pre-optimization) =====\n",
    "    old_speed = (d['avg_top2'] - avg_fig) * OLD_SPEED_WEIGHT\n",
    "    old_lay = old_layoff_factor(d['layoff_days'])\n",
    "    old_ft = old_form_trend(d['finishes'])\n",
    "    old_pace = old_analyze_pace(d['pace_e1'], d['pace_e2'], d['pace_lp'])\n",
    "    \n",
    "    # Old bounce\n",
    "    figs = d['speed_figs']\n",
    "    old_bounce = 0.0\n",
    "    if len(figs) >= 3:\n",
    "        lt = figs[:3]; cb = max(figs)\n",
    "        if lt[0] == cb and len(figs) > 3:\n",
    "            if lt[1] < lt[0] - 8: old_bounce -= 0.09\n",
    "            elif lt[1] < lt[0] - 5: old_bounce -= 0.05\n",
    "        if len(figs) >= 4 and lt[0] >= cb - 2 and lt[1] >= cb - 2: old_bounce += 0.07\n",
    "        if lt[0] > lt[1] > lt[2]: old_bounce += 0.06\n",
    "        if lt[0] < lt[1] < lt[2]: old_bounce -= 0.05\n",
    "        if max(lt) - min(lt) <= 5: old_bounce += 0.03\n",
    "    \n",
    "    old_form = old_lay + old_ft\n",
    "    # Add consistency & win bonuses (same as old calculate_form_cycle_rating)\n",
    "    recent_finishes = d['finishes']\n",
    "    if len(recent_finishes) >= 4:\n",
    "        top3 = sum(1 for f in recent_finishes[:4] if f <= 3)\n",
    "        if top3 >= 3: old_form += 0.8\n",
    "        elif top3 >= 2: old_form += 0.4\n",
    "    if recent_finishes and recent_finishes[0] == 1:\n",
    "        old_form += 0.6\n",
    "        if len(recent_finishes) >= 2 and recent_finishes[1] == 1: old_form += 0.4\n",
    "    old_form = np.clip(old_form, -3.0, 3.0)\n",
    "    \n",
    "    old_rating = d['class_rating'] + old_form + old_speed + old_pace + d['workout_bonus'] + old_bounce\n",
    "    \n",
    "    # ===== NEW rating (optimized) =====\n",
    "    new_speed = (d['avg_top2'] - avg_fig) * NEW_SPEED_WEIGHT\n",
    "    new_rating = d['class_rating'] + d['form_rating'] + new_speed + d['pace_bonus'] + d['workout_bonus'] + d['bounce_risk']\n",
    "    \n",
    "    results.append({\n",
    "        'Horse': name,\n",
    "        'OldR': old_rating, 'NewR': new_rating,\n",
    "        'Delta': new_rating - old_rating,\n",
    "        'OldRank': 0, 'NewRank': 0,\n",
    "        'BestFig': d['best_fig'],\n",
    "        'OldSpd': old_speed, 'NewSpd': new_speed,\n",
    "        'OldForm': old_form, 'NewForm': d['form_rating'],\n",
    "        'OldPace': old_pace, 'NewPace': d['pace_bonus'],\n",
    "    })\n",
    "\n",
    "# Compute ranks\n",
    "results.sort(key=lambda x: -x['OldR'])\n",
    "for i, r in enumerate(results): r['OldRank'] = i + 1\n",
    "results.sort(key=lambda x: -x['NewR'])\n",
    "for i, r in enumerate(results): r['NewRank'] = i + 1\n",
    "\n",
    "# Display\n",
    "print(f'\\n{\"Horse\":25s} {\"OldR\":>7s} {\"Rk\":>3s} {\"NewR\":>7s} {\"Rk\":>3s} {\"Œî\":>7s} {\"ŒîSpd\":>6s} {\"ŒîForm\":>6s} {\"ŒîPace\":>6s} {\"Fig\":>4s}')\n",
    "for r in results:\n",
    "    rank_change = r['OldRank'] - r['NewRank']\n",
    "    arrow = '‚Üë' if rank_change > 0 else ('‚Üì' if rank_change < 0 else '=')\n",
    "    print(f'{r[\"Horse\"]:25s} {r[\"OldR\"]:+7.3f} {r[\"OldRank\"]:3d} {r[\"NewR\"]:+7.3f} {r[\"NewRank\"]:3d} {r[\"Delta\"]:+7.3f} {r[\"NewSpd\"]-r[\"OldSpd\"]:+6.3f} {r[\"NewForm\"]-r[\"OldForm\"]:+6.2f} {r[\"NewPace\"]-r[\"OldPace\"]:+6.3f} {r[\"BestFig\"]:4d} {arrow}')\n",
    "\n",
    "# Rankings that changed\n",
    "moved = [(r['Horse'], r['OldRank'], r['NewRank']) for r in results if r['OldRank'] != r['NewRank']]\n",
    "print(f'\\nüìä Rankings changed for {len(moved)}/{len(results)} horses:')\n",
    "for h, old_rk, new_rk in sorted(moved, key=lambda x: x[1]-x[2], reverse=True):\n",
    "    direction = '‚Üë' if old_rk > new_rk else '‚Üì'\n",
    "    print(f'  {direction} {h}: #{old_rk} ‚Üí #{new_rk} ({abs(old_rk-new_rk)} spots)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 11: Probability Calibration ‚Äî Softmax & Win Probability Analysis\n",
    "print('='*80)\n",
    "print('PROBABILITY CALIBRATION ‚Äî Softmax Analysis')\n",
    "print('='*80)\n",
    "\n",
    "# Get ratings arrays (sorted by horse name for consistency)\n",
    "names_sorted = sorted(horse_data.keys())\n",
    "old_ratings = np.array([next(r['OldR'] for r in results if r['Horse'] == n) for n in names_sorted])\n",
    "new_ratings = np.array([next(r['NewR'] for r in results if r['Horse'] == n) for n in names_sorted])\n",
    "\n",
    "old_probs = APP.softmax_from_rating(old_ratings)\n",
    "new_probs = APP.softmax_from_rating(new_ratings)\n",
    "\n",
    "print(f'\\nSoftmax tau: {APP.MODEL_CONFIG[\"softmax_tau\"]}')\n",
    "old_spread = np.max(old_ratings) - np.min(old_ratings)\n",
    "new_spread = np.max(new_ratings) - np.min(new_ratings)\n",
    "print(f'Rating spread: OLD={old_spread:.3f}  NEW={new_spread:.3f}')\n",
    "print(f'Adaptive tau:  OLD={max(3.0, old_spread/3.5):.3f}  NEW={max(3.0, new_spread/3.5):.3f}')\n",
    "\n",
    "print(f'\\n{\"Horse\":25s} {\"Old%\":>7s} {\"New%\":>7s} {\"Œî%\":>7s} {\"OldOdds\":>8s} {\"NewOdds\":>8s}')\n",
    "for i, n in enumerate(names_sorted):\n",
    "    old_odds = f'{(1/old_probs[i])-1:.1f}' if old_probs[i] > 0.01 else '99+'\n",
    "    new_odds = f'{(1/new_probs[i])-1:.1f}' if new_probs[i] > 0.01 else '99+'\n",
    "    print(f'{n:25s} {old_probs[i]:7.1%} {new_probs[i]:7.1%} {new_probs[i]-old_probs[i]:+7.1%} {old_odds:>8s} {new_odds:>8s}')\n",
    "\n",
    "# Entropy (lower = more decisive model)\n",
    "old_entropy = -np.sum(old_probs * np.log(old_probs + 1e-10))\n",
    "new_entropy = -np.sum(new_probs * np.log(new_probs + 1e-10))\n",
    "max_entropy = np.log(len(names_sorted))\n",
    "print(f'\\nModel decisiveness (entropy): OLD={old_entropy:.3f}  NEW={new_entropy:.3f}  (max={max_entropy:.3f})')\n",
    "print(f'Normalized entropy: OLD={old_entropy/max_entropy:.1%}  NEW={new_entropy/max_entropy:.1%}')\n",
    "print(f'{\"‚úÖ More decisive\" if new_entropy < old_entropy else \"‚ö†Ô∏è Less decisive\"} (lower entropy = sharper separation)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e78ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 12: Multi-Race Validation (run on all available PP data)\n",
    "print('='*80)\n",
    "print('MULTI-RACE VALIDATION')\n",
    "print('='*80)\n",
    "\n",
    "for race_name, race_text in pp_data.items():\n",
    "    print(f'\\n{\"‚îÄ\"*60}')\n",
    "    print(f'RACE: {race_name}')\n",
    "    print(f'{\"‚îÄ\"*60}')\n",
    "    \n",
    "    # Parse\n",
    "    header = APP.parse_brisnet_race_header(race_text)\n",
    "    race_chunks = APP.split_into_horse_chunks(race_text)\n",
    "    \n",
    "    print(f'Track: {header.get(\"track_name\", \"?\")} | Dist: {header.get(\"distance\", \"?\")} | Type: {header.get(\"race_type\", \"?\")}')\n",
    "    print(f'Horses found: {len(race_chunks)}')\n",
    "    \n",
    "    if len(race_chunks) == 0:\n",
    "        print('  ‚ö†Ô∏è No horses parsed')\n",
    "        continue\n",
    "    \n",
    "    # Quick per-horse rating\n",
    "    race_horse_data = {}\n",
    "    for post, name, block in race_chunks:\n",
    "        speed_figs = APP.parse_speed_figures_for_block(block)\n",
    "        pace = APP.parse_e1_e2_lp_values(block)\n",
    "        pedigree = APP.parse_pedigree_snips(block)\n",
    "        try:\n",
    "            angles_df = APP.parse_angles_for_block(block)\n",
    "        except:\n",
    "            angles_df = pd.DataFrame()\n",
    "        \n",
    "        form_rating = APP.calculate_form_cycle_rating(block, pedigree, angles_df)\n",
    "        class_rating = APP.calculate_comprehensive_class_rating(\n",
    "            today_purse=header.get('purse_amount', 30000),\n",
    "            today_race_type=header.get('race_type', 'Alw'),\n",
    "            horse_block=block, pedigree=pedigree,\n",
    "            angles_df=angles_df, pp_text=race_text,\n",
    "        )\n",
    "        pace_bonus = APP.analyze_pace_figures(pace['e1'], pace['e2'], pace['lp'])\n",
    "        bounce = APP.detect_bounce_risk(speed_figs)\n",
    "        workout = APP.parse_workout_data(block)\n",
    "        try:\n",
    "            wk_bonus = APP.calculate_workout_bonus_v2(workout)\n",
    "        except:\n",
    "            wk_bonus = 0.0\n",
    "        \n",
    "        avg_fig = np.mean(sorted(speed_figs, reverse=True)[:2]) if len(speed_figs) >= 2 else (speed_figs[0] if speed_figs else 50)\n",
    "        race_horse_data[name] = {\n",
    "            'avg_top2': avg_fig,\n",
    "            'class': class_rating,\n",
    "            'form': form_rating,\n",
    "            'pace': pace_bonus,\n",
    "            'bounce': bounce,\n",
    "            'wk_bonus': wk_bonus,\n",
    "        }\n",
    "    \n",
    "    # Compute ratings\n",
    "    race_avg = np.mean([d['avg_top2'] for d in race_horse_data.values()])\n",
    "    race_ratings = {}\n",
    "    for name, d in race_horse_data.items():\n",
    "        speed_delta = (d['avg_top2'] - race_avg) * APP.MODEL_CONFIG['speed_fig_weight']\n",
    "        r = d['class'] + d['form'] + speed_delta + d['pace'] + d['wk_bonus'] + d['bounce']\n",
    "        race_ratings[name] = r\n",
    "    \n",
    "    # Probabilities\n",
    "    names = list(race_ratings.keys())\n",
    "    rats = np.array([race_ratings[n] for n in names])\n",
    "    probs = APP.softmax_from_rating(rats)\n",
    "    \n",
    "    # Print ranked\n",
    "    ranked = sorted(zip(names, rats, probs), key=lambda x: -x[1])\n",
    "    print(f'\\n  {\"Rk\":>3s} {\"Horse\":25s} {\"Rating\":>8s} {\"Prob\":>7s} {\"FairOdds\":>9s}')\n",
    "    for i, (n, r, p) in enumerate(ranked):\n",
    "        odds = f'{(1/p)-1:.1f}' if p > 0.01 else '99+'\n",
    "        print(f'  {i+1:3d} {n:25s} {r:+8.3f} {p:7.1%} {odds:>9s}')\n",
    "\n",
    "print(f'\\n‚úÖ Multi-race validation complete ‚Äî {len(pp_data)} races analyzed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 13: Component Contribution Analysis ‚Äî Rating Decomposition\n",
    "print('='*80)\n",
    "print('COMPONENT CONTRIBUTION ANALYSIS ‚Äî What drives each horse\\'s rating?')\n",
    "print('='*80)\n",
    "\n",
    "avg_fig = np.mean([d['avg_top2'] for d in horse_data.values()])\n",
    "\n",
    "print(f'\\n{\"Horse\":25s} {\"Class\":>7s} {\"Form\":>7s} {\"Speed\":>7s} {\"Pace\":>7s} {\"Bounce\":>7s} {\"WkBns\":>7s} {\"TOTAL\":>7s}')\n",
    "component_ranges = {'Class': [], 'Form': [], 'Speed': [], 'Pace': [], 'Bounce': [], 'WkBns': []}\n",
    "for name, d in horse_data.items():\n",
    "    spd = (d['avg_top2'] - avg_fig) * APP.MODEL_CONFIG['speed_fig_weight']\n",
    "    total = d['class_rating'] + d['form_rating'] + spd + d['pace_bonus'] + d['bounce_risk'] + d['workout_bonus']\n",
    "    print(f'{name:25s} {d[\"class_rating\"]:+7.2f} {d[\"form_rating\"]:+7.2f} {spd:+7.3f} {d[\"pace_bonus\"]:+7.3f} {d[\"bounce_risk\"]:+7.3f} {d[\"workout_bonus\"]:+7.3f} {total:+7.3f}')\n",
    "    component_ranges['Class'].append(d['class_rating'])\n",
    "    component_ranges['Form'].append(d['form_rating'])\n",
    "    component_ranges['Speed'].append(spd)\n",
    "    component_ranges['Pace'].append(d['pace_bonus'])\n",
    "    component_ranges['Bounce'].append(d['bounce_risk'])\n",
    "    component_ranges['WkBns'].append(d['workout_bonus'])\n",
    "\n",
    "print(f'\\n{\"Component\":10s} {\"Min\":>7s} {\"Max\":>7s} {\"Range\":>7s} {\"% of Total\":>11s}')\n",
    "total_range = sum(max(v)-min(v) for v in component_ranges.values())\n",
    "for comp, vals in component_ranges.items():\n",
    "    r = max(vals) - min(vals)\n",
    "    pct = r / total_range * 100 if total_range > 0 else 0\n",
    "    print(f'{comp:10s} {min(vals):+7.3f} {max(vals):+7.3f} {r:7.3f} {pct:10.1f}%')\n",
    "\n",
    "print(f'\\n‚úÖ Component balance check:')\n",
    "print(f'   Class should be dominant (30-40%): ‚úì' if component_ranges['Class'] else '')\n",
    "print(f'   Speed should be significant (15-25%): ', end='')\n",
    "spd_pct = (max(component_ranges['Speed'])-min(component_ranges['Speed'])) / total_range * 100 if total_range > 0 else 0\n",
    "print(f'{\"‚úÖ\" if 10 < spd_pct < 35 else \"‚ö†Ô∏è\"} ({spd_pct:.1f}%)')\n",
    "print(f'   Form should be moderate (15-25%): ', end='')\n",
    "form_pct = (max(component_ranges['Form'])-min(component_ranges['Form'])) / total_range * 100 if total_range > 0 else 0\n",
    "print(f'{\"‚úÖ\" if 10 < form_pct < 35 else \"‚ö†Ô∏è\"} ({form_pct:.1f}%)')\n",
    "print(f'   Pace should be meaningful (8-20%): ', end='')\n",
    "pace_pct = (max(component_ranges['Pace'])-min(component_ranges['Pace'])) / total_range * 100 if total_range > 0 else 0\n",
    "print(f'{\"‚úÖ\" if 5 < pace_pct < 25 else \"‚ö†Ô∏è\"} ({pace_pct:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ae452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 14: Algorithm Unit Tests & Edge Case Validation\n",
    "print('='*80)\n",
    "print('ALGORITHM UNIT TESTS ‚Äî Edge Cases & Invariant Checks')  \n",
    "print('='*80)\n",
    "\n",
    "tests_passed = 0\n",
    "tests_total = 0\n",
    "\n",
    "def check(name, condition, detail=''):\n",
    "    global tests_passed, tests_total\n",
    "    tests_total += 1\n",
    "    if condition:\n",
    "        tests_passed += 1\n",
    "        print(f'  ‚úÖ {name}')\n",
    "    else:\n",
    "        print(f'  ‚ùå {name}: {detail}')\n",
    "\n",
    "# === Speed Figure Weight ===\n",
    "print('\\n‚îÄ‚îÄ Speed Figure Weight ‚îÄ‚îÄ')\n",
    "check('speed_fig_weight is 0.15', APP.MODEL_CONFIG['speed_fig_weight'] == 0.15, f'got {APP.MODEL_CONFIG[\"speed_fig_weight\"]}')\n",
    "check('20pt fig advantage = 3.0 rating',  abs(20 * 0.15 - 3.0) < 0.01)\n",
    "\n",
    "# === Pace Analysis ===\n",
    "print('\\n‚îÄ‚îÄ Pace Analysis ‚îÄ‚îÄ')\n",
    "# Strong closer\n",
    "p = APP.analyze_pace_figures([80,82,81], [85,83,84], [95,93,92])\n",
    "check('Strong closer gets positive bonus', p > 0.05, f'got {p:.3f}')\n",
    "\n",
    "# One-dimensional speed\n",
    "p2 = APP.analyze_pace_figures([98,97,96], [90,89,88], [68,70,65])\n",
    "check('One-dim speed gets penalty', p2 < -0.05, f'got {p2:.3f}')\n",
    "\n",
    "# Empty data returns 0\n",
    "p3 = APP.analyze_pace_figures([], [], [])\n",
    "check('Empty pace data returns 0', p3 == 0.0, f'got {p3}')\n",
    "\n",
    "# Par-adjusted mode\n",
    "p4 = APP.analyze_pace_figures([90,88,89], [85,84,86], [92,91,93], e1_par=85, lp_par=88)\n",
    "check('Above-par pace gets bonus', p4 > 0.10, f'got {p4:.3f}')\n",
    "\n",
    "# === Bounce Detection ===\n",
    "print('\\n‚îÄ‚îÄ Bounce Detection ‚îÄ‚îÄ')\n",
    "b1 = APP.detect_bounce_risk([100, 85, 82, 80, 78])  # Career best + big drop\n",
    "check('Career best + drop = bounce risk', b1 < -0.05, f'got {b1:.3f}')\n",
    "\n",
    "b2 = APP.detect_bounce_risk([95, 94, 93])  # Improving trend\n",
    "check('Improving trend = positive', b2 > 0, f'got {b2:.3f}')\n",
    "\n",
    "b3 = APP.detect_bounce_risk([85, 85, 84, 86, 85])  # Very consistent\n",
    "check('Consistent figs = positive', b3 > 0, f'got {b3:.3f}')\n",
    "\n",
    "b4 = APP.detect_bounce_risk([70, 80, 88])  # Declining (lower is more recent)\n",
    "check('Declining trend = negative', b4 < 0, f'got {b4:.3f}')\n",
    "\n",
    "b5 = APP.detect_bounce_risk([90])  # Single fig\n",
    "check('Single fig returns 0', b5 == 0.0, f'got {b5}')\n",
    "\n",
    "# === Layoff Factor ===\n",
    "print('\\n‚îÄ‚îÄ Layoff Factor ‚îÄ‚îÄ')\n",
    "l1 = APP.calculate_layoff_factor(14)\n",
    "check('14-day layoff is positive', l1 > 0, f'got {l1}')\n",
    "\n",
    "l2 = APP.calculate_layoff_factor(120, num_workouts=5, workout_pattern_bonus=0.08)\n",
    "l3 = APP.calculate_layoff_factor(120, num_workouts=0)\n",
    "check('120d with 5 works < penalty of 120d with 0 works', l2 > l3, f'with works={l2:.2f}, without={l3:.2f}')\n",
    "\n",
    "l4 = APP.calculate_layoff_factor(365)\n",
    "check('365-day layoff is very negative', l4 <= -2.0, f'got {l4}')\n",
    "check('Max penalty capped at -3.0', l4 >= -3.0, f'got {l4}')\n",
    "\n",
    "# === Form Trend ===\n",
    "print('\\n‚îÄ‚îÄ Form Trend ‚îÄ‚îÄ')\n",
    "f1 = APP.calculate_form_trend([1, 1, 3, 5])\n",
    "check('Won last 2 = +2.0 (not +4.0)', f1 == 2.0, f'got {f1}')\n",
    "\n",
    "f2 = APP.calculate_form_trend([1, 5, 8])\n",
    "check('Won last only = +1.5 (not +2.5)', f2 == 1.5, f'got {f2}')\n",
    "\n",
    "f3 = APP.calculate_form_trend([2, 4, 6])\n",
    "check('Place last = +0.7 (not +1.0)', f3 == 0.7, f'got {f3}')\n",
    "\n",
    "f4 = APP.calculate_form_trend([])\n",
    "check('Empty finishes = 0', f4 == 0.0, f'got {f4}')\n",
    "\n",
    "# === Softmax ===\n",
    "print('\\n‚îÄ‚îÄ Softmax Validation ‚îÄ‚îÄ')\n",
    "test_rats = np.array([5.0, 3.0, 1.0, -1.0, -3.0])\n",
    "probs = APP.softmax_from_rating(test_rats)\n",
    "check('Softmax sums to 1.0', abs(np.sum(probs) - 1.0) < 1e-6, f'sum={np.sum(probs)}')\n",
    "check('All probs positive', np.all(probs > 0))\n",
    "check('Highest rating = highest prob', np.argmax(probs) == 0)\n",
    "check('No NaN/Inf', np.all(np.isfinite(probs)))\n",
    "\n",
    "# Edge case: identical ratings\n",
    "probs_eq = APP.softmax_from_rating(np.array([5.0, 5.0, 5.0]))\n",
    "check('Equal ratings = equal probs', np.allclose(probs_eq, 1/3, atol=0.01), f'got {probs_eq}')\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'RESULTS: {tests_passed}/{tests_total} tests passed')\n",
    "print(f'{\"=\"*60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854dac09",
   "metadata": {},
   "source": [
    "## Summary of Applied Changes (Feb 9, 2026)\n",
    "\n",
    "| # | Algorithm | Before | After | Impact | Status |\n",
    "|---|-----------|--------|-------|--------|--------|\n",
    "| 1 | `speed_fig_weight` | 0.05 | **0.15** | 20pt advantage = 3.0 (was 1.0) | ‚úÖ Applied |\n",
    "| 2 | `analyze_pace_figures()` | Flat ¬±0.07 | **Par-adjusted ¬±0.45** | Pace = 15-20% of rating | ‚úÖ Applied |\n",
    "| 3 | `calculate_layoff_factor()` | No mitigation | **60% max workout relief** | Horses with works no longer punished equally | ‚úÖ Applied |\n",
    "| 4 | `calculate_form_trend()` | +4.0 max | **+2.0 max** | Form = modifier (33% of class range) | ‚úÖ Applied |\n",
    "| 5 | `calculate_hot_trainer_bonus()` | -2.5 for 0% | **-1.2 capped** | Single stat can't override rating | ‚úÖ Applied |\n",
    "| 6 | `detect_bounce_risk()` | ¬±0.09 | **¬±0.25** | Regression-based trend + consistency | ‚úÖ Applied |\n",
    "| 7 | `R_ENHANCE_ADJ` cap | [-1.0, 1.5] | **[-2.0, 3.0]** | Speed figs no longer clipped | ‚úÖ Applied |\n",
    "\n",
    "### Methodology\n",
    "- **Speed figures**: Beyer/Quirin/Benter (1994) ‚Äî 30-40% predictive power\n",
    "- **Pace analysis**: Par-adjusted + recency-weighted + energy distribution\n",
    "- **Bounce detection**: Linear regression slope + standard deviation + career-relative\n",
    "- **Layoff mitigation**: Per-workout 12% reduction, bullet work extra 15%\n",
    "- **Form trend**: Proportional to ClassRating range (33% not 67%)\n",
    "- **Trainer penalty**: Sample-size-aware, doesn't override multi-component model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
